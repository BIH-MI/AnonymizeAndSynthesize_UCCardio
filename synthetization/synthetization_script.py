# /**
#  * Use Case Cardiology HiGHmed Data Anonymisation
#  * Copyright (C) 2023 - Berlin Institute of Health
#  * <p>
#  * Use of this software is govered by the Business Source License included in the LICENSE.md file.
#  * Change Date: 14.08.2028, Change License: Academic Free License v3.0
#  * On the date above, in accordance with the Business Source License, use of this software will be governed by the
#  * open source license AFL v3.0 or as specified in the LICENSE.md file.
#  *
#  * Unless required by applicable law or agreed to in writing, software
#  * distributed under the License is distributed on an "AS IS" BASIS,
#  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
#  * See the License for the specific language governing permissions and
#  * limitations under the License.
#  */

import os
from argparse import ArgumentParser

import ASyH
import pandas as pd

from ASyH_scripts.utility import get_metadata
from evaluation.local_utils import read_data, MEDICAL_SCORE
from preprocessing.preprocess_UCC import preprocess, drop_unused_columns

DELETE_TEMP = False


def run_synthetization(synth_input_file, synth_output_file, columns_spec=None):
    """
    Executes the data synthetization using ASyH
    :param synth_input_file: filepath to the preprocessed highmed cardio dataset
    :param synth_output_file: filepath to where the synthesized data should be saved to
    """
    if not os.path.isabs(synth_input_file):
        synth_input_file = os.path.join(os.getcwd(), synth_input_file.lstrip("./"))
    if not os.path.isabs(synth_output_file):
        synth_output_file = os.path.join(os.getcwd(), synth_output_file.lstrip("./"))

    real_data = pd.read_csv(synth_input_file)
    raw_metadata = get_metadata()
    # reducing the input data to the subset defined in the metadata:
    real_data = real_data[raw_metadata['columns'].keys()]

    # as a shortcut, these are the results of the best scored ASyH pipeline,
    # GaussianCopulaModel.  The below settings were taken from the output model.
    # This model was generated by running:
    #   asyh = ASyH.Application()
    #   asyh.synthesize(synth_input_file, metadata=raw_metadata)
    columns_distributions = {'age': 'gaussian_kde',
                             'bmi': 'gamma',
                             'sys_bp_m': 'gamma',
                             'hf_duration': 'truncnorm',
                             'lvef_m': 'gaussian_kde',
                             'creatinine_m': 'gaussian_kde',
                             'sodium_m': 'beta',
                             'hb_m': 'truncnorm',
                             'egfr_m': 'beta'}

    # if we need to restrict to a data subset (columns_spec):
    if columns_spec is not None:
        # re-add 'alias'
        columns_spec = ['alias'] + columns_spec
        print(f'feature_set = {columns_spec}')
        real_data = real_data[columns_spec]
        raw_metadata['columns'] = {col: raw_metadata['columns'][col] for col in columns_spec}
        columns_distributions = {col: columns_distributions[col] for col in columns_distributions if
                                 col in columns_spec}

    metadata = ASyH.Metadata(raw_metadata)
    input_data = ASyH.Data(real_data, metadata=metadata)

    GCM_model = ASyH.GaussianCopulaModel(
        input_data,
        override_args={'numerical_distributions': columns_distributions, 'default_distribution': 'uniform'}
    )

    synth_data = GCM_model.synthesize()
    synth_data.to_csv(synth_output_file, index=False)

    return pd.read_csv(synth_output_file)


def synthesize_ucc_cardio_data(df, columns_spec=None,
                               temp_file="./temp/anon_input.csv",
                               output_file="./temp/anon_output.csv"):
    """
    Method to synthesize the use case cardio dataset using the ASyH
    :param df: table with use case data
    :param temp_file: filepath to a temporary file, that is preprocessed for the anonymization
    :param output_file: filepath to the anonymized use case cardio csv-file
    """

    df.drop(['Unnamed: 0', 'hstnt_m', 'hstnt_u', 'ntprobnp_m', 'ntprobnp_u'],
            axis=1, inplace=True, errors='ignore')
    df.to_csv(temp_file, index=False, sep=",", na_rep='NULL')
    synthesized_data = run_synthetization(temp_file, output_file, columns_spec=columns_spec)

    if DELETE_TEMP:
        os.remove(temp_file)
        os.remove(output_file)

    return synthesized_data


def get_scored_data(scored_dataset, score: MEDICAL_SCORE):
    """Filter dataset for availbility of specific SCORE in a scored dataset
    SCORED_DATASET. Scores will not be contained in the resulting DataFrame.
    """

    SCORE_COLS = ['biohf_v1_1',
                  'biohf_v1_3',
                  'maggic_score_1',
                  'maggic_score_3']

    try:
        if score == MEDICAL_SCORE.BIOHF:
            raw = scored_dataset[scored_dataset['biohf_v1_1'].notnull()]
        elif score == MEDICAL_SCORE.MAGGIC:
            raw = scored_dataset[scored_dataset['maggic_score_1'].notnull()]
        else:
            raw = scored_dataset
    except KeyError as excpt:
        print("Could not find score column in data!")
        raise (excpt)

    return raw.drop(columns=SCORE_COLS, errors='ignore')


def save_df_to_file(filename, df):
    df.to_csv(filename, index=False)
    return pd.read_csv(filename)


def focused_synthesize_ucc_cardio_data(df, score, temp_file="./temp/anon_input.csv",
                                       output_file="./temp/anon_output.csv"):
    """Take a dataframe DF also containing the scores and train and synthesize
    for the datasubset with avalable SCORE.
    """
    indata = save_df_to_file(temp_file, get_scored_data(df, score))
    return synthesize_ucc_cardio_data(df, temp_file, output_file)
